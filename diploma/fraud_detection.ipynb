{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Time         V1         V2         V3         V4         V5        V6  \\\n",
      "0   28755 -30.552380  16.713389 -31.103685   6.534984 -22.105532 -4.977692   \n",
      "1   28726 -29.876366  16.434525 -30.558697   6.505862 -21.665654 -4.940356   \n",
      "2   28692 -29.200329  16.155701 -30.013712   6.476731 -21.225810 -4.902997   \n",
      "3  102572 -28.709229  22.057729 -27.855811  11.845013 -18.983813  6.474115   \n",
      "4   28658 -28.524268  15.876923 -29.468732   6.447591 -20.786000 -4.865613   \n",
      "\n",
      "          V7         V8         V9  ...       V22       V23       V24  \\\n",
      "0 -20.371514  20.007208  -3.565738  ... -2.288686 -1.460544  0.183179   \n",
      "1 -20.081391  19.587773  -3.591491  ... -2.232252 -1.412803  0.178731   \n",
      "2 -19.791248  19.168327  -3.617242  ... -2.175815 -1.365104  0.174286   \n",
      "3 -43.557242 -41.044261 -13.320155  ...  8.316275  5.466230  0.023854   \n",
      "4 -19.501084  18.748872  -3.642990  ... -2.119376 -1.317450  0.169846   \n",
      "\n",
      "        V25       V26       V27       V28  Amount  Class  Fraud  \n",
      "0  2.208209 -0.208824  1.232636  0.356660   99.99      1   True  \n",
      "1  2.156042 -0.209385  1.255649  0.364530   99.99      1   True  \n",
      "2  2.103868 -0.209944  1.278681  0.372393   99.99      1   True  \n",
      "3 -1.527145 -0.145225 -5.682338 -0.439134    0.01      1   True  \n",
      "4  2.051687 -0.210502  1.301734  0.380246   99.99      1   True  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = df.drop(['Class', 'Fraud'],1)\n",
    "y_all = df['Fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (30 total features):\n",
      "['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n"
     ]
    }
   ],
   "source": [
    "#we want continous vars that are integers for our input data, so lets remove any categorical vars\n",
    "def preprocess_features(X):\n",
    "    ''' Preprocesses the football data and converts catagorical variables into dummy variables. '''\n",
    "    \n",
    "    # Initialize new output DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Investigate each feature column for the data\n",
    "    for col, col_data in X.iteritems():\n",
    "\n",
    "        # If data type is categorical, convert to dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)\n",
    "                    \n",
    "        # Collect the revised columns\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print(\"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Shuffle and split the dataset into training and testing set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, \n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 4,\n",
    "                                                    stratify = y_all)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "\n",
    "svc_classifier = svm.SVC()\n",
    "svc_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_predict = svc_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[91 11]\n",
      " [24 74]]\n",
      "Accuracy: 0.825\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_test, y_predict))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[74, 24],\n",
       "       [11, 91]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_predict, labels=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.79      0.89      0.84       102\n",
      "        True       0.87      0.76      0.81        98\n",
      "\n",
      "    accuracy                           0.82       200\n",
      "   macro avg       0.83      0.82      0.82       200\n",
      "weighted avg       0.83      0.82      0.82       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8236294517807123\n"
     ]
    }
   ],
   "source": [
    "print(metrics.balanced_accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.04432984696803\n"
     ]
    }
   ],
   "source": [
    "print(metrics.log_loss(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
